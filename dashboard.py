"""
Trading Sentiment Analysis Dashboard
=====================================
Run:  streamlit run dashboard.py
Requires: dashboard_data.pkl in same folder (generated by notebook Part F)
"""

import streamlit as st
import pandas as pd
import numpy as np
import pickle
import matplotlib.pyplot as plt
import matplotlib.gridspec as gridspec
import seaborn as sns
import warnings
warnings.filterwarnings("ignore")

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# CONFIG
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
st.set_page_config(
    page_title="Trading Ã— Sentiment Dashboard",
    page_icon="ğŸ“Š",
    layout="wide",
    initial_sidebar_state="expanded",
)

SENTIMENT_ORDER = ["Extreme Fear", "Fear", "Neutral", "Greed", "Extreme Greed"]
PALETTE = {
    "Extreme Fear":  "#d62728",
    "Fear":          "#ff7f0e",
    "Neutral":       "#8c8c8c",
    "Greed":         "#2ca02c",
    "Extreme Greed": "#1a7a1a",
}
REGIME_PALETTE = {"Fear": "#d62728", "Neutral": "#8c8c8c", "Greed": "#2ca02c"}

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# LOAD DATA
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
@st.cache_data
def load_data():
    try:
        with open("dashboard_data.pkl", "rb") as f:
            d = pickle.load(f)
        return d
    except FileNotFoundError:
        return None

data = load_data()

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# SIDEBAR
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
with st.sidebar:
    st.image("https://img.icons8.com/fluency/96/combo-chart.png", width=60)
    st.title("âš™ï¸ Filters")

    if data is None:
        st.error("dashboard_data.pkl not found.\nRun the notebook first.")
        st.stop()

    merged_df       = data["merged_df"].copy()
    daily           = data["daily"].copy()
    acct_feat       = data["acct_feat"].copy()
    cluster_profile = data["cluster_profile"].copy()
    best_model      = data["best_model"]
    le              = data["le"]
    feature_cols    = data["feature_cols"]

    # Date range
    merged_df["date"] = pd.to_datetime(merged_df["date"])
    min_d = merged_df["date"].min().date()
    max_d = merged_df["date"].max().date()
    date_range = st.date_input("Date range", value=[min_d, max_d],
                               min_value=min_d, max_value=max_d)

    # Sentiment filter
    selected_sent = st.multiselect(
        "Sentiment filter", SENTIMENT_ORDER, default=SENTIMENT_ORDER
    )

    # Regime filter
    all_regimes = sorted(merged_df["regime"].dropna().unique().tolist())
    selected_reg = st.multiselect("Regime filter", all_regimes, default=all_regimes)

    # Archetype filter
    if "archetype" in acct_feat.columns:
        all_arch = sorted(acct_feat["archetype"].dropna().unique().tolist())
        selected_arch = st.multiselect("Archetype filter", all_arch, default=all_arch)
    else:
        selected_arch = []

    st.markdown("---")
    st.caption("Built with Streamlit + Matplotlib/Seaborn")

# Apply filters
if len(date_range) == 2:
    start_d, end_d = pd.Timestamp(date_range[0]), pd.Timestamp(date_range[1])
    mask = (
        (merged_df["date"] >= start_d)
        & (merged_df["date"] <= end_d)
        & (merged_df["classification"].isin(selected_sent))
        & (merged_df["regime"].isin(selected_reg))
    )
    df_f = merged_df[mask].copy()
else:
    df_f = merged_df.copy()

if selected_arch and "archetype" in acct_feat.columns:
    arch_accts = acct_feat[acct_feat["archetype"].isin(selected_arch)]["Account"]
    df_arch = df_f[df_f["Account"].isin(arch_accts)]
else:
    df_arch = df_f.copy()

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# HEADER KPIs
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
st.title("ğŸ“ˆ Trading Ã— Sentiment Analysis Dashboard")
st.caption(f"Showing **{len(df_f):,}** trades from {df_f['date'].min().date()} to {df_f['date'].max().date()}")

col1, col2, col3, col4, col5 = st.columns(5)
col1.metric("Total Trades",     f"{len(df_f):,}")
col2.metric("Unique Traders",   f"{df_f['Account'].nunique():,}")
col3.metric("Win Rate",         f"{df_f['is_win'].mean()*100:.1f}%")
col4.metric("Avg PnL / Trade",  f"${df_f['Closed PnL'].mean():.1f}")
col5.metric("Avg Position Size",f"${df_f['Size USD'].mean():,.0f}")

st.markdown("---")

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# TABS
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
tab1, tab2, tab3, tab4, tab5 = st.tabs([
    "ğŸ“Š Performance",
    "ğŸ§  Behaviour",
    "ğŸ‘¥ Segments",
    "ğŸ¤– Predictions",
    "ğŸ” Archetypes",
])

sns.set_theme(style="whitegrid")


# â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
# â•‘  TAB 1 â€” PERFORMANCE                                        â•‘
# â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
with tab1:
    st.subheader("Performance Metrics by Sentiment")

    # Summary table
    pnl_tbl = (df_f.groupby("classification")["Closed PnL"]
               .agg(["mean","median","sum","std"])
               .reindex(SENTIMENT_ORDER).round(2)
               .rename(columns={"mean":"Mean PnL","median":"Median PnL",
                                 "sum":"Total PnL","std":"PnL Std"}))
    wr_tbl = (df_f.groupby("classification")["is_win"]
              .mean().reindex(SENTIMENT_ORDER) * 100).round(1)
    pnl_tbl["Win Rate %"] = wr_tbl
    trade_cnt = df_f.groupby("classification").size().reindex(SENTIMENT_ORDER)
    pnl_tbl["# Trades"] = trade_cnt

    st.dataframe(pnl_tbl.style
                 .background_gradient(subset=["Mean PnL","Win Rate %"], cmap="RdYlGn")
                 .format({"Mean PnL":"${:.1f}","Total PnL":"${:,.0f}",
                           "Win Rate %":"{:.1f}%","# Trades":"{:,}"}),
                 use_container_width=True)

    col_a, col_b = st.columns(2)

    with col_a:
        st.markdown("**Mean PnL per Trade by Sentiment**")
        colors = [PALETTE.get(s, "grey") for s in pnl_tbl.index]
        fig, ax = plt.subplots(figsize=(7, 4))
        bars = ax.bar(pnl_tbl.index, pnl_tbl["Mean PnL"], color=colors,
                      edgecolor="black", linewidth=0.5)
        ax.axhline(0, color="black", linewidth=0.8, linestyle="--")
        ax.set_xticklabels(pnl_tbl.index, rotation=30, ha="right", fontsize=9)
        ax.set_ylabel("USD"); ax.set_title("Mean Closed PnL per Trade")
        for bar, val in zip(bars, pnl_tbl["Mean PnL"]):
            ax.text(bar.get_x()+bar.get_width()/2, bar.get_height()+0.3,
                    f"${val:.1f}", ha="center", fontsize=7)
        plt.tight_layout()
        st.pyplot(fig); plt.close()

    with col_b:
        st.markdown("**Win Rate (%) by Sentiment**")
        fig, ax = plt.subplots(figsize=(7, 4))
        bars = ax.bar(pnl_tbl.index, pnl_tbl["Win Rate %"], color=colors,
                      edgecolor="black", linewidth=0.5)
        ax.axhline(50, color="red", linewidth=0.8, linestyle="--", label="50%")
        ax.set_ylim(0, 65); ax.legend(fontsize=8)
        ax.set_xticklabels(pnl_tbl.index, rotation=30, ha="right", fontsize=9)
        ax.set_ylabel("%"); ax.set_title("Win Rate (%) by Sentiment")
        for bar, val in zip(bars, pnl_tbl["Win Rate %"]):
            ax.text(bar.get_x()+bar.get_width()/2, bar.get_height()+0.3,
                    f"{val:.1f}%", ha="center", fontsize=7)
        plt.tight_layout()
        st.pyplot(fig); plt.close()

    # Daily PnL time series
    st.markdown("**Daily Total PnL Over Time**")
    daily_pnl_ts = (df_f.groupby("date")["Closed PnL"].sum().reset_index())
    daily_pnl_ts["rolling7"] = daily_pnl_ts["Closed PnL"].rolling(7, min_periods=1).mean()
    fig, ax = plt.subplots(figsize=(14, 3.5))
    ax.fill_between(daily_pnl_ts["date"], daily_pnl_ts["Closed PnL"],
                    alpha=0.3, color="#4c72b0")
    ax.plot(daily_pnl_ts["date"], daily_pnl_ts["rolling7"],
            color="#d62728", linewidth=1.5, label="7-day MA")
    ax.axhline(0, color="black", linewidth=0.7)
    ax.set_ylabel("Total PnL (USD)"); ax.legend(fontsize=9); ax.grid(alpha=0.3)
    plt.tight_layout()
    st.pyplot(fig); plt.close()


# â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
# â•‘  TAB 2 â€” BEHAVIOUR                                          â•‘
# â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
with tab2:
    st.subheader("Trader Behaviour Across Sentiment Regimes")

    days_per = (df_f[["date","classification"]].drop_duplicates()
                .groupby("classification").size().reindex(SENTIMENT_ORDER))
    raw_cnt  = df_f.groupby("classification").size().reindex(SENTIMENT_ORDER)
    norm_f   = (raw_cnt / days_per).round(1)

    ls_ratio = (df_f.groupby(["classification","Side"]).size()
                .unstack(fill_value=0).reindex(SENTIMENT_ORDER))
    ls_ratio["L/S"] = (ls_ratio["BUY"] / ls_ratio["SELL"]).round(3)

    df_f["leverage_proxy2"] = np.where(
        df_f["Start Position"].abs() > 0,
        df_f["Size USD"] / df_f["Start Position"].abs(), np.nan)
    avg_lev = df_f.groupby("classification")["leverage_proxy2"].mean().reindex(SENTIMENT_ORDER).round(2)
    avg_sz  = df_f.groupby("classification")["Size USD"].mean().reindex(SENTIMENT_ORDER).round(0)

    beh_df = pd.DataFrame({
        "Trades/Day": norm_f,
        "Avg Leverage": avg_lev,
        "L/S Ratio": ls_ratio["L/S"],
        "Avg Size USD": avg_sz,
    })
    st.dataframe(beh_df.style
                 .background_gradient(subset=["Trades/Day","Avg Leverage"], cmap="Blues")
                 .format({"Trades/Day":"{:.1f}","Avg Leverage":"{:.2f}",
                           "L/S Ratio":"{:.3f}","Avg Size USD":"${:,.0f}"}),
                 use_container_width=True)

    cols = st.columns(2)
    metrics_info = [
        ("Trades/Day", "Normalised Trade Frequency", "Trades per day"),
        ("L/S Ratio",  "Long/Short Ratio (>1 = more buys)", "BUY/SELL ratio"),
    ]
    for i, (metric, title, ylab) in enumerate(metrics_info):
        with cols[i]:
            fig, ax = plt.subplots(figsize=(7, 4))
            clrs = [PALETTE.get(s,"grey") for s in beh_df.index]
            ax.bar(beh_df.index, beh_df[metric], color=clrs,
                   edgecolor="black", linewidth=0.5)
            if metric == "L/S Ratio":
                ax.axhline(1.0, color="red", linewidth=0.8, linestyle="--", label="Balanced")
                ax.legend(fontsize=8)
            ax.set_title(title, fontweight="bold")
            ax.set_ylabel(ylab)
            ax.set_xticklabels(beh_df.index, rotation=30, ha="right", fontsize=9)
            plt.tight_layout()
            st.pyplot(fig); plt.close()

    st.markdown("**Average Position Size (USD) by Sentiment**")
    fig, ax = plt.subplots(figsize=(12, 3.5))
    clrs = [PALETTE.get(s,"grey") for s in beh_df.index]
    ax.bar(beh_df.index, beh_df["Avg Size USD"], color=clrs, edgecolor="black")
    ax.set_ylabel("USD"); ax.set_title("Average Position Size")
    ax.set_xticklabels(beh_df.index, rotation=20, ha="right")
    for bar, val in zip(ax.patches, beh_df["Avg Size USD"]):
        ax.text(bar.get_x()+bar.get_width()/2, bar.get_height()+50,
                f"${val:,.0f}", ha="center", fontsize=8)
    plt.tight_layout()
    st.pyplot(fig); plt.close()


# â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
# â•‘  TAB 3 â€” SEGMENTS                                           â•‘
# â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
with tab3:
    st.subheader("Trader Segment Analysis")

    # Build segments on filtered data
    seg_stats = df_f.groupby("Account").agg(
        trade_count  = ("Closed PnL","count"),
        total_pnl    = ("Closed PnL","sum"),
        win_rate     = ("is_win","mean"),
        avg_size_usd = ("Size USD","mean"),
    ).reset_index()

    lev_med  = seg_stats["avg_size_usd"].median()
    freq_med = seg_stats["trade_count"].median()
    wr_med   = seg_stats["win_rate"].median()

    seg_stats["lev_seg"]  = np.where(seg_stats["avg_size_usd"] >= lev_med,  "High Exposure","Low Exposure")
    seg_stats["freq_seg"] = np.where(seg_stats["trade_count"]  >= freq_med, "Frequent","Infrequent")
    seg_stats["win_seg"]  = np.where(seg_stats["win_rate"]     >= wr_med,   "Consistent Winner","Inconsistent")

    df_seg = df_f.merge(seg_stats[["Account","lev_seg","freq_seg","win_seg"]], on="Account", how="left")

    seg_choice = st.selectbox("Choose segment dimension",
                              ["Exposure (High/Low)", "Frequency", "Win Consistency"])
    seg_map = {
        "Exposure (High/Low)": "lev_seg",
        "Frequency": "freq_seg",
        "Win Consistency": "win_seg",
    }
    seg_col = seg_map[seg_choice]

    col_x, col_y = st.columns(2)

    with col_x:
        st.markdown(f"**Win Rate Heatmap â€” {seg_choice}**")
        pivot = (df_seg.groupby([seg_col,"classification"])["is_win"]
                 .mean().unstack() * 100
                 ).reindex(columns=SENTIMENT_ORDER).round(1)
        fig, ax = plt.subplots(figsize=(8, 3))
        sns.heatmap(pivot, annot=True, fmt=".1f", cmap="RdYlGn", ax=ax,
                    linewidths=0.5, cbar_kws={"label":"Win Rate %"}, vmin=30, vmax=60)
        ax.set_xlabel(""); ax.set_ylabel("")
        ax.set_xticklabels(SENTIMENT_ORDER, rotation=30, ha="right", fontsize=8)
        plt.tight_layout()
        st.pyplot(fig); plt.close()

    with col_y:
        st.markdown(f"**Mean PnL Heatmap â€” {seg_choice}**")
        pivot2 = (df_seg.groupby([seg_col,"classification"])["Closed PnL"]
                  .mean().unstack()
                  ).reindex(columns=SENTIMENT_ORDER).round(1)
        fig, ax = plt.subplots(figsize=(8, 3))
        sns.heatmap(pivot2, annot=True, fmt=".1f", cmap="RdYlGn", ax=ax,
                    linewidths=0.5, cbar_kws={"label":"Mean PnL USD"})
        ax.set_xlabel(""); ax.set_ylabel("")
        ax.set_xticklabels(SENTIMENT_ORDER, rotation=30, ha="right", fontsize=8)
        plt.tight_layout()
        st.pyplot(fig); plt.close()

    # Box plot
    st.markdown(f"**PnL Distribution by {seg_choice} and Regime**")
    df_seg_plot = df_seg.copy()
    df_seg_plot["Closed PnL (clip)"] = df_seg_plot["Closed PnL"].clip(-2000, 2000)
    fig, ax = plt.subplots(figsize=(12, 4))
    sns.boxplot(data=df_seg_plot, x="regime", y="Closed PnL (clip)",
                hue=seg_col, ax=ax, order=["Fear","Neutral","Greed"],
                palette="Set2", flierprops={"marker":".","markersize":2,"alpha":0.3})
    ax.axhline(0, color="black", linewidth=0.8, linestyle="--")
    ax.set_xlabel("Regime"); ax.set_ylabel("PnL USD (clipped Â±2000)")
    ax.legend(title=seg_col, fontsize=8)
    plt.tight_layout()
    st.pyplot(fig); plt.close()


# â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
# â•‘  TAB 4 â€” PREDICTIONS                                        â•‘
# â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
with tab4:
    st.subheader("ğŸ¤– Next-Day Profitability Predictor")

    st.markdown("""
    Enter today's trading conditions to predict tomorrow's likely PnL bucket.
    The model uses sentiment, behaviour, and rolling features trained on historical data.
    """)

    col1, col2, col3 = st.columns(3)
    with col1:
        inp_sent = st.selectbox("Today's Market Sentiment", SENTIMENT_ORDER, index=2)
        inp_wr   = st.slider("Today Win Rate (%)", 0, 100, 45) / 100
        inp_tc   = st.number_input("Today Trade Count", 1, 500, 10)
    with col2:
        inp_size = st.number_input("Avg Position Size (USD)", 100, 100000, 5000, step=100)
        inp_lev  = st.number_input("Leverage Proxy", 0.1, 50.0, 2.0, step=0.1)
        inp_buy  = st.slider("Buy Ratio (%)", 0, 100, 50) / 100
    with col3:
        inp_pnl1 = st.number_input("PnL Lag 1 (yesterday)", -10000, 10000, 100, step=50)
        inp_pnl2 = st.number_input("PnL Lag 2 (2 days ago)", -10000, 10000, 50, step=50)
        inp_fee  = st.number_input("Total Fees Paid Today", 0.0, 1000.0, 10.0, step=1.0)

    sent_map_ui = {"Extreme Fear":1,"Fear":2,"Neutral":3,"Greed":4,"Extreme Greed":5}

    if st.button("ğŸ”® Predict Tomorrow", type="primary"):
        try:
            # Build feature row matching training feature_cols
            # We fill unknowns with training medians
            daily_filt = daily.copy()
            medians = daily_filt[feature_cols].median()

            row = medians.copy()
            row["sent_score"]        = sent_map_ui[inp_sent]
            row["trade_count"]       = inp_tc
            row["win_rate_day"]      = inp_wr
            row["avg_size"]          = inp_size
            row["avg_lev"]           = inp_lev
            row["buy_ratio"]         = inp_buy
            row["total_fee"]         = inp_fee
            row["pnl_lag1"]          = inp_pnl1
            row["pnl_lag2"]          = inp_pnl2
            row["trades_lag1"]       = inp_tc
            row["daily_pnl_roll3"]   = (inp_pnl1 + inp_pnl2) / 2
            row["trade_count_roll3"] = inp_tc
            row["win_rate_day_roll3"]= inp_wr
            row["avg_size_roll3"]    = inp_size

            # Set sentiment dummies
            for col in [c for c in feature_cols if c.startswith("sent_")]:
                row[col] = 0
            sent_key = f"sent_{inp_sent}"
            if sent_key in row.index:
                row[sent_key] = 1

            X_pred = pd.DataFrame([row[feature_cols]])
            proba  = best_model.predict_proba(X_pred)[0]
            pred   = le.inverse_transform([proba.argmax()])[0]
            classes = le.classes_

            st.markdown("---")
            col_r1, col_r2 = st.columns([1, 2])

            emoji = {"Profitable": "ğŸŸ¢", "Breakeven": "ğŸŸ¡", "Loss": "ğŸ”´"}
            with col_r1:
                st.metric("Predicted PnL Bucket",
                          f"{emoji.get(pred,'')} {pred}",
                          delta=f"Confidence: {proba.max()*100:.1f}%")

            with col_r2:
                fig, ax = plt.subplots(figsize=(6, 3))
                clrs = ["#2ca02c" if c=="Profitable" else
                        "#ff7f0e" if c=="Breakeven"  else "#d62728"
                        for c in classes]
                bars = ax.barh(classes, proba * 100, color=clrs, edgecolor="black")
                ax.set_xlabel("Probability (%)")
                ax.set_xlim(0, 100)
                ax.set_title("Prediction Confidence")
                for bar, val in zip(bars, proba*100):
                    ax.text(val+0.5, bar.get_y()+bar.get_height()/2,
                            f"{val:.1f}%", va="center", fontsize=9)
                plt.tight_layout()
                st.pyplot(fig); plt.close()

        except Exception as e:
            st.error(f"Prediction failed: {e}\n\nEnsure the notebook Part F has been run to generate dashboard_data.pkl")

    # Feature importance
    st.markdown("---")
    st.markdown("**Feature Importance (trained model)**")
    try:
        if hasattr(best_model, "feature_importances_"):
            fi = best_model.feature_importances_
        else:
            fi = np.abs(best_model.named_steps["clf"].coef_[0])
        fi_df = pd.DataFrame({"feature": feature_cols, "importance": fi})
        fi_df = fi_df.sort_values("importance", ascending=True).tail(12)
        fig, ax = plt.subplots(figsize=(10, 4.5))
        ax.barh(fi_df["feature"], fi_df["importance"], color="#4c72b0", edgecolor="black")
        ax.set_xlabel("Importance"); ax.set_title("Top Feature Importances")
        plt.tight_layout()
        st.pyplot(fig); plt.close()
    except Exception:
        st.info("Feature importance not available for this model type.")


# â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
# â•‘  TAB 5 â€” ARCHETYPES                                         â•‘
# â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
with tab5:
    st.subheader("ğŸ” Behavioural Archetypes (KMeans Clustering)")

    if "archetype" not in acct_feat.columns:
        st.warning("Archetype data not found. Run the clustering section (Part E) in the notebook first.")
    else:
        # Profile table
        st.markdown("**Archetype Summary**")
        prof_cols = ["archetype","total_trades","avg_pnl","pnl_std",
                     "win_rate","avg_size","avg_leverage","buy_ratio"]
        prof_show = cluster_profile.reset_index()[
            [c for c in prof_cols if c in cluster_profile.reset_index().columns]
        ].round(3)
        st.dataframe(prof_show.style
                     .background_gradient(subset=["win_rate","avg_leverage"], cmap="RdYlGn")
                     .format({"avg_pnl":"${:.1f}","avg_size":"${:,.0f}",
                               "win_rate":"{:.1%}","buy_ratio":"{:.1%}",
                               "avg_leverage":"{:.2f}","pnl_std":"${:.1f}"}),
                     use_container_width=True)

        col_l, col_r = st.columns(2)

        with col_l:
            st.markdown("**PCA â€” 2D Cluster Scatter**")
            fig, ax = plt.subplots(figsize=(7, 5))
            arch_list = acct_feat["archetype"].unique().tolist()
            cmap = plt.cm.tab10.colors
            for ci, arch in enumerate(arch_list):
                mask = acct_feat["archetype"] == arch
                ax.scatter(acct_feat.loc[mask,"pca1"], acct_feat.loc[mask,"pca2"],
                           c=[cmap[ci % 10]], s=35, alpha=0.6, label=arch)
                cx = acct_feat.loc[mask,"pca1"].mean()
                cy = acct_feat.loc[mask,"pca2"].mean()
                ax.annotate(f"C{ci}", (cx,cy), fontsize=10, fontweight="bold",
                            ha="center", va="center",
                            bbox=dict(boxstyle="round,pad=0.3", fc="white", alpha=0.7))
            ax.legend(fontsize=7, loc="best")
            ax.set_xlabel("PC1"); ax.set_ylabel("PC2")
            ax.set_title("Trader Clusters (PCA 2D)")
            plt.tight_layout()
            st.pyplot(fig); plt.close()

        with col_r:
            st.markdown("**Archetype Size Distribution**")
            arch_counts = acct_feat["archetype"].value_counts()
            fig, ax = plt.subplots(figsize=(7, 5))
            wedges, texts, autotexts = ax.pie(
                arch_counts.values,
                labels=arch_counts.index,
                autopct="%1.1f%%",
                colors=[plt.cm.tab10.colors[i] for i in range(len(arch_counts))],
                startangle=140, pctdistance=0.8
            )
            for at in autotexts:
                at.set_fontsize(8)
            ax.set_title("Trader Count by Archetype")
            plt.tight_layout()
            st.pyplot(fig); plt.close()

        # Archetype Ã— sentiment heatmap
        if "archetype" in df_arch.columns or "Account" in df_arch.columns:
            merged_arch = df_f.merge(acct_feat[["Account","archetype"]], on="Account", how="left")
            st.markdown("**Win Rate (%) per Archetype Ã— Sentiment**")
            wr_arch = (merged_arch.groupby(["archetype","classification"])["is_win"]
                       .mean().unstack() * 100
                       ).reindex(columns=SENTIMENT_ORDER).round(1)
            fig, ax = plt.subplots(figsize=(12, max(3, len(wr_arch)*0.9)))
            sns.heatmap(wr_arch, annot=True, fmt=".1f", cmap="RdYlGn",
                        ax=ax, linewidths=0.5, vmin=30, vmax=60,
                        cbar_kws={"label":"Win Rate %"})
            ax.set_xlabel(""); ax.set_ylabel("")
            ax.set_xticklabels(SENTIMENT_ORDER, rotation=30, ha="right", fontsize=9)
            plt.tight_layout()
            st.pyplot(fig); plt.close()

        # Strategy recommendations
        st.markdown("---")
        st.markdown("### ğŸ’¡ Archetype-Specific Strategy Rules")
        rules = {
            "Disciplined Winner":    "âœ… **Maintain current strategy.** Regime-agnostic â€” no special adjustments needed. This archetype is consistently profitable.",
            "High-Risk Speculator":  "âš ï¸ **During Fear/Extreme Fear:** Cap position sizes at 60% of your norm and avoid market orders. **During Greed:** Momentum strategies work well â€” but set hard stop-losses.",
            "Overtrader (Churner)": "ğŸ”´ **All regimes:** Halve your daily trade count target. Fee drag is your primary enemy. Focus on quality over quantity.",
            "Passive Loss-Taker":    "ğŸŸ¡ **During Fear:** Avoid entering new positions. **During Greed:** Consider only trend-following entries with tight stops.",
            "Moderate Opportunist":  "ğŸ”µ **Neutral/Fear:** Stick to small sizes. **Greed:** Expand position size modestly (+20%) on confirmed setups.",
        }
        for arch, rule in rules.items():
            if arch in acct_feat["archetype"].values:
                with st.expander(f"ğŸ“Œ {arch}"):
                    st.markdown(rule)

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# FOOTER
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
st.markdown("---")
st.caption("Trading Ã— Fear & Greed Sentiment Analysis | Built with Streamlit, Matplotlib, Seaborn, Scikit-learn")
